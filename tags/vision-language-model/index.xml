<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Vision-Language Model on The AI Talks</title>
    <link>http://theaitalks.org/tags/vision-language-model/</link>
    <description>Recent content in Vision-Language Model on The AI Talks</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 22 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://theaitalks.org/tags/vision-language-model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Distilling Vision-Language Models on Millions of Videos</title>
      <link>http://theaitalks.org/talks/2024/0222-1/</link>
      <pubDate>Sat, 22 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>http://theaitalks.org/talks/2024/0222-1/</guid>
      <description>Speaker Yue Zhao is a fourth-year PhD student at the University of Texas at Austin, supervised by Prof. Philipp Krähenbühl. He obtained his MPhil degree from the Multimedia Laboratory at the Chinese University of Hong Kong, supervised by Prof. Dahua Lin. More previously, he got his Bachelor&amp;rsquo;s degree from Tsinghua University. His current research interests are computer vision, particularly video analysis and understanding. He is a recipient of the 2024-2025 NVIDIA fellowship.</description>
    </item>
    
  </channel>
</rss>
