<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Bio: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.
Homepage: https://mitchellnw.github.io/.
Abstract I&rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models.">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Finetuning Vision Models: Improving Robustness and Accuracy"/>
<meta name="twitter:description" content="Speaker Bio: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.
Homepage: https://mitchellnw.github.io/.
Abstract I&rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models."/>

<meta property="og:title" content="Finetuning Vision Models: Improving Robustness and Accuracy" />
<meta property="og:description" content="Speaker Bio: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.
Homepage: https://mitchellnw.github.io/.
Abstract I&rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2022/1013/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2022-10-13T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-10-13T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2022/1013/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.ed2d2a97f7f0cc62d94e43aee036e965a8d3521cdc17bbb4b7d39e8dab764d99.css" integrity="sha256-7S0ql/fwzGLZTkOu4DbpZajTUhzcF7u0t9Oejat2TZk=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.107.0">


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2022/1013/">
              Finetuning Vision Models: Improving Robustness and Accuracy
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-10-13T00:00:00Z">
                13-10-2022
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/mitchell-wortsman/">Mitchell Wortsman</a></div>

          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/transfer-learning/">transfer learning</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/robustness/">robustness</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/foundation-models/">foundation models</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/computer-vision/">computer vision</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p><strong>Bio</strong>: Mitchell is a fourth year PhD student at the University of Washington. His research interests include large models, transfer learning, and robustness.</p>
<p><strong>Homepage</strong>: <a href="https://mitchellnw.github.io/">https://mitchellnw.github.io/</a>.</p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>I&rsquo;ll discuss methods for fine-tuning which improve model robustness and accuracy. These methods leverage the observation that fine-tuned models often appear to lie in a single low error region. To improve robustness, we therefore interpolate the weights of the pre-trained and fine-tuned models. This achieves the best of both worlds: capturing the robustness of the pre-trained model and the in-distribution accuracy of the fine-tuned model. We then generalize this approach to interpolate the weights of multiple fine-tuned models. The conventional procedure for maximizing model performance is to try many different hyperparameters, then select the best model and discard the remainder. We propose an alternative to this procedure in the context of fine-tuning: we average the weights of multiple fine-tuned models, and are often able to produce a better model with no added inference cost.</p>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vUZi2Ehq0KI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2022 -
    
    2025
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
