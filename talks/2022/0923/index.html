<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Bio: Associate Professor Zongyuan Ge conducts interdisciplinary research at the boundary between medical artificial intelligence, computer-aided diagnosis, biomedical engineering, medical imaging and machine learning and is a multi-award winning medical information science and technology entrepreneur. His research leverages cutting-edge AI technologies using large-scale multi-modality medical data including imaging, medical records, gene data and models the clinicians’ medical knowledge underlying tasks like diagnosis, prognosis and treatment for eye (ophthalmology), skin (dermatology), heart (cardiovascular) and neurodegeneration diseases such as epilepsy and multiple sclerosis.">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="MMAI: Close the loop for Medical AI application"/>
<meta name="twitter:description" content="Speaker Bio: Associate Professor Zongyuan Ge conducts interdisciplinary research at the boundary between medical artificial intelligence, computer-aided diagnosis, biomedical engineering, medical imaging and machine learning and is a multi-award winning medical information science and technology entrepreneur. His research leverages cutting-edge AI technologies using large-scale multi-modality medical data including imaging, medical records, gene data and models the clinicians’ medical knowledge underlying tasks like diagnosis, prognosis and treatment for eye (ophthalmology), skin (dermatology), heart (cardiovascular) and neurodegeneration diseases such as epilepsy and multiple sclerosis."/>

<meta property="og:title" content="MMAI: Close the loop for Medical AI application" />
<meta property="og:description" content="Speaker Bio: Associate Professor Zongyuan Ge conducts interdisciplinary research at the boundary between medical artificial intelligence, computer-aided diagnosis, biomedical engineering, medical imaging and machine learning and is a multi-award winning medical information science and technology entrepreneur. His research leverages cutting-edge AI technologies using large-scale multi-modality medical data including imaging, medical records, gene data and models the clinicians’ medical knowledge underlying tasks like diagnosis, prognosis and treatment for eye (ophthalmology), skin (dermatology), heart (cardiovascular) and neurodegeneration diseases such as epilepsy and multiple sclerosis." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2022/0923/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2022-09-23T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-09-23T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2022/0923/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.0411908cd3963ed60595f15ef37a4261db7d1e9952ded16b48e874e1fb55d724.css" integrity="sha256-BBGQjNOWPtYFlfFe83pCYdt9HplS3tFrSOh04ftV1yQ=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.101.0" />


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2022/0923/">
              MMAI: Close the loop for Medical AI application
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2022-09-23T00:00:00Z">
                23-09-2022
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/zongyuan-ge/">Zongyuan Ge</a></div>

          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/healthcare/">healthcare</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/machine-learning/">machine learning</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p><strong>Bio</strong>: Associate Professor Zongyuan Ge conducts interdisciplinary research at the boundary between medical artificial intelligence, computer-aided diagnosis, biomedical engineering, medical imaging and machine learning and is a multi-award winning medical information science and technology entrepreneur. His research leverages cutting-edge AI technologies using large-scale multi-modality medical data including imaging, medical records, gene data and models the clinicians’ medical knowledge underlying tasks like diagnosis, prognosis and treatment for eye (ophthalmology), skin (dermatology), heart (cardiovascular) and neurodegeneration diseases such as epilepsy and multiple sclerosis. He is also one of Australia’s most in-demand experts in technology, including medical robotics and artificial intelligence, and is a passionate science communicator.</p>
<p>He currently holds the position of Associate Professor at the Monash University Vice-Chancellor and Provost Office as well as Faculty of Engineering, Research Affiliate at the Australian Centre for Robotic Vision, NVIDIA AI Fellow, the Chief Scientist at Monash-Airdoc Research Centre and Chief Research Officer at Eyetelligence. He is the founding director of the Monash Medical AI group (<a href="https://www.monash.edu/mmai-group">https://www.monash.edu/mmai-group</a>) with over fully-funded 20+ PhD students (internal + external), 6 Research Fellows, and 10+ Research Master/FYP students.</p>
<p>His research has helped attract more than 25+ million dollars in funding as either primary chief investigator or leading chief investigator from grant bodies, including the National Health and Medical Research Council (NHMRC), Medical Research Future Fund (MRFF), The Australian Research Data Commons (ARDC) and industry funding from NVIDIA, Molemap and Airdoc. Zongyuan’s research papers have been published in top-tier journals and conferences such as The Lancet Digital Health, The British Medical Journal, JAMA, Bioinformatics, Hypertension, IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Transactions on Medical Imaging, NeurIPS, CVPR, ICCV, ICLR, KDD, AAAI and MICCAI. His citations h-index is 29, with 5000+ citations only four years post his PhD.</p>
<p>He has led and contributed to several international research projects in the areas of dermatology, ophthalmology, radiology and neurology with major industry companies like IBM Watson Health, medical technology unicorn company Airdoc/Eyetelligence and medical/healthcare services providers such as Molemap Clinic, The Alfred Health, Royal Melbourne Hospital, and Princess Alexandra Hospital. His work has been recognised by many international and national awards, including the 200 Most Qualified Young Researchers in Computer and Mathematics by the Scientific Committee of the Heidelberg Laureate Foundation, IBM Scientific Research Accomplishment Award, IBM Manager Choice Award and Monash Exceptional Achievement Award.</p>
<p><strong>Homepage</strong>: <a href="https://zongyuange.github.io/">https://zongyuange.github.io/</a>.</p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>In this talk, I will speak about the overview and research vision for the Monash Medical AI (<a href="https://www.monash.edu/mmai-group)">https://www.monash.edu/mmai-group)</a>. Two case studies (dermatology AI and ophthalmology AI) will be introduced in this talk.</p>
<p>[Ophthalmology AI] We have developed one of the world first CFDA &amp; CE &amp; TGA certified [6] multi-label retinal disease diagnosis systems (backed up by publications in top-tier journals and conferences [1,2,3,4,5]) which seek out the telltale signs of dozens of chronic illnesses and conditions such as diabetes, hypertension, arteriosclerosis, optic nerve disease, and many more. The Comprehensive AI Retinal Expert (CARE) system, which is an essential part of our product line and can identify the 14 most common retinal abnormalities using 207,228 colour fundus photographs derived from 16 clinical settings with different disease distributions. It has been validated using 21 867 photographs and externally tested using 18,136 photographs prospectively collected from 35 real-world settings across China and published in The Lancet Digital Health [8].</p>
<p>[Skin (dermatology) AI] Partnered with one of the largest skin clinics in Australia and NZ, Molemap (<a href="https://www.molemap.net.au/">https://www.molemap.net.au/</a>) and IBM Watson Health in 2019, as the Primary Chief Investigator, we have developed the world-first AI embedded handhold camera diagnostic system that uses the fusion of various modalities of skin images and clinical information for skin cancer screening. This is the algorithm current under the Improving Skin Cancer Management With Artificial Intelligence (SMARTI) trial directly investigate the problem of how AI system could assist doctors in the real-world setting.</p>
<p><strong>References</strong>:</p>
<ol>
<li>W.He, X.Wang, X.Zhao, L.Wu, H.Lu, Z.Ge, Quasi-Hierarchical Learning for Exudate and Hemorrhage Segmentation on Fundus Images, Information Fusion 2021</li>
<li>L.Ju, X.Wang, Z.Xin, P.Bonnington, T.Drummond, Z.Ge, Leveraging Regular Fundus Images for Training UWF Fundus Diagnosis Models via Adversarial Learning and Pseudo-Labeling, IEEE Transaction on Medical Imaging, 2021</li>
<li>J.Xiong et al. Z.Ge, … , Improve Unseen Domain Generalization via Enhanced Local Color Transformation, MICCAI 2020</li>
<li>H.Lin, Z.Ge et al. A universal artificial intelligence platform for collaborative management of cataracts, British Journal of Ophthalmology (BJO), 2019</li>
<li>Z.Ge, Y.Xing, R.Zeng, D.Mahapatra, J.Seah, M,Law, T.Drummond, Adversarial Pulmonary Pathology Translation for Pairwise Chest X-ray Data Augmentation, International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2019</li>
<li>News press on Airdoc CFDA: <a href="https://equalocean.com/news/201902021385">https://equalocean.com/news/201902021385</a></li>
<li>Microsoft press on medical AI products: <a href="https://news.microsoft.com/apac/features/ai-and-preventative-healthcare-diagnosis-in-the-blink-of-an-eye/">https://news.microsoft.com/apac/features/ai-and-preventative-healthcare-diagnosis-in-the-blink-of-an-eye/</a></li>
<li>Lin, D., Xiong, J., Liu, C., Zhao, L., Li, Z., Yu, S., Wu, X., Z.Ge., Hu, X., Wang, B. and Fu, M., 2021. Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study. The Lancet Digital Health, 2021.</li>
</ol>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<iframe width="560" height="315" src="https://www.youtube.com/embed/KtnkBTEQ_BI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
    2022
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
