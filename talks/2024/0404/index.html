<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Haohan Wang is an assistantprofessor in the School of Information Sciences at the University of IllinoisUrbana-Champaign. His research focuses on the development of trustworthymachine learning methods for computational biology and healthcare applications.In his work, he uses statistical analysis and deep learning methods, with anemphasis on data analysis using methods least influenced by spurious signals.Wang earned his PhD in computer science through the Language TechnologiesInstitute of Carnegie Mellon University. He is also an organizer of TrustworthyMachine Learning Initiative.">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Guardian of Trust in Language Models: Automatic Jailbreak and Systematic Defense"/>
<meta name="twitter:description" content="Speaker Haohan Wang is an assistantprofessor in the School of Information Sciences at the University of IllinoisUrbana-Champaign. His research focuses on the development of trustworthymachine learning methods for computational biology and healthcare applications.In his work, he uses statistical analysis and deep learning methods, with anemphasis on data analysis using methods least influenced by spurious signals.Wang earned his PhD in computer science through the Language TechnologiesInstitute of Carnegie Mellon University. He is also an organizer of TrustworthyMachine Learning Initiative."/>

<meta property="og:title" content="Guardian of Trust in Language Models: Automatic Jailbreak and Systematic Defense" />
<meta property="og:description" content="Speaker Haohan Wang is an assistantprofessor in the School of Information Sciences at the University of IllinoisUrbana-Champaign. His research focuses on the development of trustworthymachine learning methods for computational biology and healthcare applications.In his work, he uses statistical analysis and deep learning methods, with anemphasis on data analysis using methods least influenced by spurious signals.Wang earned his PhD in computer science through the Language TechnologiesInstitute of Carnegie Mellon University. He is also an organizer of TrustworthyMachine Learning Initiative." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2024/0404/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2024-04-04T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-04-04T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2024/0404/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.ed2d2a97f7f0cc62d94e43aee036e965a8d3521cdc17bbb4b7d39e8dab764d99.css" integrity="sha256-7S0ql/fwzGLZTkOu4DbpZajTUhzcF7u0t9Oejat2TZk=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.107.0">


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2024/0404/">
              Guardian of Trust in Language Models: Automatic Jailbreak and Systematic Defense
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2024-04-04T00:00:00Z">
                04-04-2024
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/haohan-wang/">Haohan Wang</a></div>

          
          
        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Haohan Wang is an assistantprofessor in the School of Information Sciences at the University of IllinoisUrbana-Champaign. His research focuses on the development of trustworthymachine learning methods for computational biology and healthcare applications.In his work, he uses statistical analysis and deep learning methods, with anemphasis on data analysis using methods least influenced by spurious signals.Wang earned his PhD in computer science through the Language TechnologiesInstitute of Carnegie Mellon University. He is also an organizer of TrustworthyMachine Learning Initiative.</p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Large Language Models (LLMs) excel in Natural Language Processing (NLP) with human-like text generation, butthe misuse of them has raised a significant concern. In this talk, we introducean innovative system designed to address these challenges. Our system leveragesLLMs to play different roles, simulating various user personas to generate&quot;jailbreaks&quot; – prompts that can induce LLMs to produce outputscontrary to ethical standards or specific guidelines. Utilizing a knowledgegraph, our method efficiently creates new jailbreaks, testing the LLMs&rsquo;adherence to governmental and ethical guidelines. Empirical validation ondiverse models, including Vicuna-13B, LongChat-7B, Llama-2-7B, and ChatGPT, hasdemonstrated its efficacy. The system&rsquo;s application extends to Visual LanguageModels, highlighting its versatility in multimodal contexts.</p>
<p>The second part of our talk shifts focus to defensivestrategies against such jailbreaks. Recent studies have uncovered variousattacks that can manipulate LLMs, including manual and gradient-basedjailbreaks. Our work delves into the development of robust prompt optimizationas a novel defense mechanism, inspired from principled solutions fromtrustworthy machine learning. This approach involves system prompts – parts ofthe input text inaccessible to users – and aims to counter both manual andgradient-based attacks effectively. Despite current methods, adaptive attackslike GCG remain a challenge, necessitating a formalized defensive objective.Our research proposes such an objective and demonstrates how robust promptoptimization can enhance the safety of LLMs, safeguarding against realisticthreat models and adaptive attacks.</p>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Do7K1fDGSRQ?si=g1U4BGY3-s1xxlCB" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2022 -
    
    2025
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
