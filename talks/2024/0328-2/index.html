<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Jiafei Duan is currently a second-year PhD student at the Robotics and State Estimation Lab, University of Washington, under the advisory of Professor Dieter Fox and Ranjay Krishna. His research interest lies in intersection between robot learning, embodied AI and computer vision. Mr Duan served as the lead author in several embodied AI and robotics papers published in top-tier AI conferences and journals (including NeurIPS, IJCAI, EMNLP, ICLR, ICCV, ECCV, CoRL, and IEEE TETCI).">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Towards democratising robot learning for all"/>
<meta name="twitter:description" content="Speaker Jiafei Duan is currently a second-year PhD student at the Robotics and State Estimation Lab, University of Washington, under the advisory of Professor Dieter Fox and Ranjay Krishna. His research interest lies in intersection between robot learning, embodied AI and computer vision. Mr Duan served as the lead author in several embodied AI and robotics papers published in top-tier AI conferences and journals (including NeurIPS, IJCAI, EMNLP, ICLR, ICCV, ECCV, CoRL, and IEEE TETCI)."/>

<meta property="og:title" content="Towards democratising robot learning for all" />
<meta property="og:description" content="Speaker Jiafei Duan is currently a second-year PhD student at the Robotics and State Estimation Lab, University of Washington, under the advisory of Professor Dieter Fox and Ranjay Krishna. His research interest lies in intersection between robot learning, embodied AI and computer vision. Mr Duan served as the lead author in several embodied AI and robotics papers published in top-tier AI conferences and journals (including NeurIPS, IJCAI, EMNLP, ICLR, ICCV, ECCV, CoRL, and IEEE TETCI)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2024/0328-2/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2024-03-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-03-28T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2024/0328-2/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.ed2d2a97f7f0cc62d94e43aee036e965a8d3521cdc17bbb4b7d39e8dab764d99.css" integrity="sha256-7S0ql/fwzGLZTkOu4DbpZajTUhzcF7u0t9Oejat2TZk=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.107.0">


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2024/0328-2/">
              Towards democratising robot learning for all
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2024-03-28T00:00:00Z">
                28-03-2024
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/jiafei-duan/">Jiafei Duan</a></div>

          
          
        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Jiafei Duan is currently a second-year PhD student at the Robotics and State Estimation Lab, University of Washington, under the advisory of Professor Dieter Fox and Ranjay Krishna. His research interest lies in intersection between robot learning, embodied AI and computer vision. Mr Duan served as the lead author in several embodied AI and robotics papers published in top-tier AI conferences and journals (including NeurIPS, IJCAI, EMNLP, ICLR, ICCV, ECCV, CoRL, and IEEE TETCI). He has also received Singapore&rsquo;s prestigious National Science (PhD) Scholarship for his PhD studies.</p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Training a generalist robotic foundational model relies on two key factors: the scalability of robot data collection and the generalization capabilities of modern behaviour cloning models (e.g., PerAct, ACT, RVT). To address these challenges, I first introduced AR2-D2, a novel system for collecting demonstrations that eliminates the need for specialized training or real robots during data collection, thus enabling the manipulation of diverse objects. Implemented as an iOS application, AR2-D2 allows users to record videos of themselves manipulating objects while simultaneously gathering essential data for training real robots. Our system proves effective in training behaviour cloning agents for real object manipulation, showing that training with our augmented reality (AR) data is as effective as training with real-world robot demonstrations. Additionally, I will present Colosseum, a new simulation benchmark featuring 20 diverse manipulation tasks that allow for the systematic evaluation of models across 12 axes of environmental perturbations. Colosseum facilitates the systematic assessment of behaviour cloning models&rsquo; robustness against these perturbations. Our results demonstrate a strong correlation between simulation outcomes and real-world experiment perturbations, affirming Colosseum&rsquo;s ecological validity. Thus, I aim to address the two critical challenges in scaling robotic manipulation models.</p>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<iframe width="560" height="315" src="https://www.youtube.com/embed/76swatHTLbs?si=iW03MvwFGcjDFas3" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2022 -
    
    2026
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
