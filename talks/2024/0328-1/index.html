<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Shashank Tripathi is a final year PhD student at the Max Planck Institute for Intelligent Systems (MPI-IS), where he is advised by Prof. Michael Black. Previously, he worked as an Applied Scientist at Amazon. Shashank earned his Masters from the Robotics Institute at Carnegie Mellon University, under the supervision of Prof. Kris Kitani. His research broadly lies at the intersection of computer vision, machine learning, and computer graphics, with a particular focus on 3D modeling of human bodies, modeling human-object interactions, and physics-inspired human motion understanding.">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Physics-informed Modeling of Dynamic Humans and their Interactions"/>
<meta name="twitter:description" content="Speaker Shashank Tripathi is a final year PhD student at the Max Planck Institute for Intelligent Systems (MPI-IS), where he is advised by Prof. Michael Black. Previously, he worked as an Applied Scientist at Amazon. Shashank earned his Masters from the Robotics Institute at Carnegie Mellon University, under the supervision of Prof. Kris Kitani. His research broadly lies at the intersection of computer vision, machine learning, and computer graphics, with a particular focus on 3D modeling of human bodies, modeling human-object interactions, and physics-inspired human motion understanding."/>

<meta property="og:title" content="Physics-informed Modeling of Dynamic Humans and their Interactions" />
<meta property="og:description" content="Speaker Shashank Tripathi is a final year PhD student at the Max Planck Institute for Intelligent Systems (MPI-IS), where he is advised by Prof. Michael Black. Previously, he worked as an Applied Scientist at Amazon. Shashank earned his Masters from the Robotics Institute at Carnegie Mellon University, under the supervision of Prof. Kris Kitani. His research broadly lies at the intersection of computer vision, machine learning, and computer graphics, with a particular focus on 3D modeling of human bodies, modeling human-object interactions, and physics-inspired human motion understanding." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2024/0328-1/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2024-03-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2024-03-28T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2024/0328-1/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.ed2d2a97f7f0cc62d94e43aee036e965a8d3521cdc17bbb4b7d39e8dab764d99.css" integrity="sha256-7S0ql/fwzGLZTkOu4DbpZajTUhzcF7u0t9Oejat2TZk=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.107.0">


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2024/0328-1/">
              Physics-informed Modeling of Dynamic Humans and their Interactions
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2024-03-28T00:00:00Z">
                28-03-2024
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/shashank-tripathi/">Shashank Tripathi</a></div>

          
          
        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Shashank Tripathi is a final year PhD student at the Max Planck Institute for Intelligent Systems (MPI-IS), where he is advised by Prof. Michael Black. Previously, he worked as an Applied Scientist at Amazon. Shashank earned his Masters from the Robotics Institute at Carnegie Mellon University, under the supervision of Prof. Kris Kitani. His research broadly lies at the intersection of computer vision, machine learning, and computer graphics, with a particular focus on 3D modeling of human bodies, modeling human-object interactions, and physics-inspired human motion understanding.</p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Humans constantly interact with the physical world, and such interactions are guided by the laws of physics. To understand humans and their actions, computers need automatic methods to reconstruct and model the body in 3D. State-of-the-art (SOTA) 3D human pose estimation methods have made rapid progress, estimating 3D humans that align well with image features in the camera view. Similarly, there has been rapid progress in training models that generate human motions either unconditionally or conditioned on text or previous motions. However, most methods ignore the fact that people move in a scene, interact with it, and receive physical support by contacting it. This is a deal-breaker for inherently 3D applications, such as biomechanics, augmented/virtual reality (AR/VR), interactive entertainment, and gaming. In this talk, I will discuss our work towards integrating differentiable physics and biomechanics in data-driven training. Specifically, I will introduce IPMAN, a 3D human pose estimation method that leverages novel intuitive physics terms to estimate physically plausible 3D bodies from a color image in a &ldquo;stable&rdquo; configuration. Next, I will discuss our recent work on shape-conditioned human motion generation that extends IPMAN&rsquo;s differentiable physics terms to dynamic humans. Lastly, I&rsquo;ll present DECO, a novel method for accurately estimating 3D human-scene and human-object contact in complex scenarios depicted in real-world images. Trained on the DAMON dataset, DECO leverages detailed vertex-level annotations to effectively model physical interactions. I&rsquo;ll also discuss how we curated and scaled 3D contact annotations tailored for real-world images in the DAMON dataset.</p>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Coming soon. Stay tuned. :-)</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2022 -
    
    2026
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
