<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Yinghao Xu is a final-year Ph.D. student at Multimedia Lab (MMLab), Department of Information Engineering in The Chinese University of Hong Kong. His supervisor is Prof. Dahua Lin and Prof. Bolei Zhou. He is very interested in generative models and neural rendering, particularly in 3D generative models. During his Ph.D., he is fortunate to visit Stanford computational group, working with Prof. Gordon Wetzstein. Many of his papers have been awarded as oral representation and best paper candidate at CVPR, ECCV, NeurIPS and ICLR.">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="3D Generation from Unstructured Single-view Data"/>
<meta name="twitter:description" content="Speaker Yinghao Xu is a final-year Ph.D. student at Multimedia Lab (MMLab), Department of Information Engineering in The Chinese University of Hong Kong. His supervisor is Prof. Dahua Lin and Prof. Bolei Zhou. He is very interested in generative models and neural rendering, particularly in 3D generative models. During his Ph.D., he is fortunate to visit Stanford computational group, working with Prof. Gordon Wetzstein. Many of his papers have been awarded as oral representation and best paper candidate at CVPR, ECCV, NeurIPS and ICLR."/>

<meta property="og:title" content="3D Generation from Unstructured Single-view Data" />
<meta property="og:description" content="Speaker Yinghao Xu is a final-year Ph.D. student at Multimedia Lab (MMLab), Department of Information Engineering in The Chinese University of Hong Kong. His supervisor is Prof. Dahua Lin and Prof. Bolei Zhou. He is very interested in generative models and neural rendering, particularly in 3D generative models. During his Ph.D., he is fortunate to visit Stanford computational group, working with Prof. Gordon Wetzstein. Many of his papers have been awarded as oral representation and best paper candidate at CVPR, ECCV, NeurIPS and ICLR." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2023/0511/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2023-05-11T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-05-11T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2023/0511/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.ed2d2a97f7f0cc62d94e43aee036e965a8d3521cdc17bbb4b7d39e8dab764d99.css" integrity="sha256-7S0ql/fwzGLZTkOu4DbpZajTUhzcF7u0t9Oejat2TZk=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.107.0">


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2023/0511/">
              3D Generation from Unstructured Single-view Data
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2023-05-11T00:00:00Z">
                11-05-2023
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/yinghao-xu/">Yinghao Xu</a></div>

          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/3d-generation/">3D generation</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Yinghao Xu is a final-year Ph.D. student at Multimedia Lab (MMLab), Department of Information Engineering in The Chinese University of Hong Kong. His supervisor is Prof. Dahua Lin and Prof. Bolei Zhou. He is very interested in generative models and neural rendering, particularly in 3D generative models. During his Ph.D., he is fortunate to visit Stanford computational group, working with Prof. Gordon Wetzstein. Many of his papers have been awarded as oral representation and best paper candidate at CVPR, ECCV, NeurIPS and ICLR.</p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Pixel-based content creation has made remarkable progress thanks to 2D generative models. However, a deeper understanding of the 3D world beyond image space is necessary for a wide range of real-world applications, such as AR and VR. Traditional 3D content creation authoring pipelines require professional expertise and significant financial investment to build large 3D datasets. In this talk, I will introduce our recent works in enabling 3D generative modeling from unstructured 2D images, especially in single-view data, by introducing powerful and effective 3D representations. It paves the way for generating high-quality 3D assets efficiently. Additionally, we also generalize the 3D generative model to in-the-wild objects and complex scenes, enabling 3D image generation on ImageNet and controllable 3D scene synthesis. These efforts are integral to our long-term vision of enabling high-quality, user-friendly 3D content creation for a broad audience.</p>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Coming soon. Stay tuned. :-)</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2022 -
    
    2025
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
