<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="The AI Talks">
<meta name="description" content="Speaker Akari Asai is a Ph.D. student in the Paul G. Allen School of Computer Science &amp; Engineering at the University of Washington, advised by Prof. Hannaneh Hajishirzi. Her research lies in natural language processing and machine learning. Her recent research focuses on question answering / IR, multilingual NLP, retrieval-augmented LMs, and efficiency. She received the IBM Fellowship in 2022 and the Nakajima Foundation Fellowship in 2019 and is selected as a 2022 EECS Rising Star.">
<meta name="keywords" content="The AI Talks, AI, Machine Learning, Computer Science">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Adaptive and Trustworthy NLP with Retrieval for Information Access for Everyone"/>
<meta name="twitter:description" content="Speaker Akari Asai is a Ph.D. student in the Paul G. Allen School of Computer Science &amp; Engineering at the University of Washington, advised by Prof. Hannaneh Hajishirzi. Her research lies in natural language processing and machine learning. Her recent research focuses on question answering / IR, multilingual NLP, retrieval-augmented LMs, and efficiency. She received the IBM Fellowship in 2022 and the Nakajima Foundation Fellowship in 2019 and is selected as a 2022 EECS Rising Star."/>

<meta property="og:title" content="Adaptive and Trustworthy NLP with Retrieval for Information Access for Everyone" />
<meta property="og:description" content="Speaker Akari Asai is a Ph.D. student in the Paul G. Allen School of Computer Science &amp; Engineering at the University of Washington, advised by Prof. Hannaneh Hajishirzi. Her research lies in natural language processing and machine learning. Her recent research focuses on question answering / IR, multilingual NLP, retrieval-augmented LMs, and efficiency. She received the IBM Fellowship in 2022 and the Nakajima Foundation Fellowship in 2019 and is selected as a 2022 EECS Rising Star." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://theaitalks.org/talks/2023/0302/" /><meta property="article:section" content="talks" />
<meta property="article:published_time" content="2023-05-09T00:00:00+00:00" />
<meta property="article:modified_time" content="2023-05-09T00:00:00+00:00" />




  <title>The AI Talks</title>

  
  <link rel="canonical" href="http://theaitalks.org/talks/2023/0302/">
  

  <link rel="preload" href="/fonts/forkawesome-webfont.woff2?v=1.2.0" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.min.5d9e92b56f30af2bb26c7c6bc87dbb3136248859d5bdf7b663786291f71d6055.css" integrity="sha256-XZ6StW8wryuybHxryH27MTYkiFnVvfe2Y3hikfcdYFU=" crossorigin="anonymous" media="screen" />





  
  
    
    
    <link rel="stylesheet" href="/css/coder-dark.min.39e41a7f16bdf8cb16e43cae7d714fa1016f1d2d2898a5b3f27f42c9979204e2.css" integrity="sha256-OeQafxa9&#43;MsW5DyufXFPoQFvHS0omKWz8n9CyZeSBOI=" crossorigin="anonymous" media="screen" />
  



   
  
    
    <link rel="stylesheet" href="/css/custom.min.ed2d2a97f7f0cc62d94e43aee036e965a8d3521cdc17bbb4b7d39e8dab764d99.css" integrity="sha256-7S0ql/fwzGLZTkOu4DbpZajTUhzcF7u0t9Oejat2TZk=" crossorigin="anonymous" media="screen" />
  





  <link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">


  

  <meta name="generator" content="Hugo 0.107.0">


  

</head>







<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    <a class="navigation-title" href="/">
      The AI Talks
    </a>
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link" href="/about/">About</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/organizers/">Organizers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/speakers/">Speakers</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/talks/">Talks</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link" href="/subscribe/">Subscribe</a>
            </li>
          
        
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://theaitalks.org/talks/2023/0302/">
              Adaptive and Trustworthy NLP with Retrieval for Information Access for Everyone
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa fa-calendar" aria-hidden="true"></i>
              <time datetime="2023-05-09T00:00:00Z">
                09-05-2023
              </time>
            </span>
          </div>
          <div class="authors">
  <i class="fa fa-user" aria-hidden="true"></i>
    <a href="/authors/akari-asai/">Akari Asai</a></div>

          
          <div class="tags">
  <i class="fa fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/tags/large-language-models/">large language models</a>
    </span>
      <span class="separator">•</span>
    <span class="tag">
      <a href="/tags/nlp/">NLP</a>
    </span></div>

        </div>
      </header>

      <div>
        
        <h1 id="speaker">
  Speaker
  <a class="heading-link" href="#speaker">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Akari Asai is a Ph.D. student in the Paul G. Allen School of Computer Science &amp; Engineering at the University of Washington, advised by Prof. Hannaneh Hajishirzi. Her research lies in natural language processing and machine learning. Her recent research focuses on question answering / IR, multilingual NLP, retrieval-augmented LMs, and efficiency. She received the IBM Fellowship in 2022 and the Nakajima Foundation Fellowship in 2019 and is selected as a 2022 EECS Rising Star.  Prior to UW, she obtained a B.E. degree in Electrical Engineering and Computer Science from the University of Tokyo.</p>
<p>Akari&rsquo;s homepage: <a href="https://akariasai.github.io/">https://akariasai.github.io/</a></p>
<h1 id="abstract">
  Abstract
  <a class="heading-link" href="#abstract">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Large language models (LLMs) have shown great success in various natural language processing (NLP) tasks, inspiring the development of real-world applications of LLMs, such as conversational search systems. However, these LLMs suffer from major issues such as hallucinations, staleness, and the need for prohibitively large models, due to their reliance on memorizing everything within their parameters (parametric memories). To address these limitations, I am developing efficient and trustworthy NLP systems with retrieval, which incorporate non-parametric memories stored as text.  In this talk, I will discuss my recent work on analyzing and developing more reliable and efficient retrieval-augmented LMs. First, I will discuss our analysis of the memorization of LLMs and how non-parametric memories can complement the shortcomings of relying on parametric memories. Next, I will introduce our general-purpose retrieval systems, which enable the development of robust and competitive retrieval-augmented LMs. In particular, we introduce the first instruction-following retrieval system that can adapt to a new task with a prompt describing the task. Finally, I will describe our new generative model, which learns to focus on supportive non-parametric memories rather than irrelevant ones. I will conclude with a discussion of the remaining challenges and wider applications.</p>
<h1 id="video">
  Video
  <a class="heading-link" href="#video">
    <i class="fa fa-link" aria-hidden="true"></i>
  </a>
</h1>
<p>Coming soon. Stay tuned. :-)</p>

      </div>


      <footer>
        


        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ©
    
      2022 -
    
    2023
     The AI Talks 
    ·
    
    Powered by <a href="https://gohugo.io/">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/">Coder</a>.
    
  </section>
</footer>

  </main>

  
  
  <script src="/js/coder.min.236049395dc3682fb2719640872958e12f1f24067bb09c327b233e6290c7edac.js" integrity="sha256-I2BJOV3DaC&#43;ycZZAhylY4S8fJAZ7sJwyeyM&#43;YpDH7aw="></script>
  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7L2H1Q8FMQ"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-7L2H1Q8FMQ', { 'anonymize_ip': false });
}
</script>


  

  

  

  

  

  

  
</body>

</html>
